---
title: "Five Minute Analytics: Central Limit Theorem"
output: rmarkdown::github_document
header-includes: 
  \usepackage{float}
  \usepackage{mathtools}
---

## The Central Limit Theorem

According to probability theory

>*The frequency distribution of samples means from a population tend towards a normal distribution with the same mean and standard deviation.*

## Why do I care?

As analysts, rarely do we have all the data about what we are trying to model (in other words, we don't know the true population). Instead, we have samples from the unknown, true population.

Which individual sample mean will reflect the true population mean?  

```{r, echo=FALSE, fig.align="center"}
par(fig=c(0,.9,0,.9), mar=c(1,1,1,1))
par(fig=c(0,.3,.3,.6),cex=.5)
hist(rt(1:100, df = 4),main='Population ~ t(4)')
#add samples
par(fig=c(.35,0.6,.65,.9), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 1")
abline(v = mean(smp), col="red", lwd=3, lty=1)
par(fig=c(.65,0.9,.65,.9), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 2")
abline(v = mean(smp), col="red", lwd=3, lty=1)
par(fig=c(.35,0.6,.35,.6), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 3")
abline(v = mean(smp), col="red", lwd=3, lty=1)
par(fig=c(.65,0.9,.35,.6), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 4")
abline(v = mean(smp), col="red", lwd=3, lty=1)
par(fig=c(.35,0.6,0.05,.3), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 5")
abline(v = mean(smp), col="red", lwd=3, lty=1)
par(fig=c(.65,0.9,0.05,.3), new=TRUE)
smp <-rt(1:100, df = 4) 
hist(smp, main="Sample 6")
abline(v = mean(smp), col="red", lwd=3, lty=1)
```

*We don't know.*

However, according to the Central Limit Theorem, the individual sample means will cluster around the true population mean. Provided it is large enough, our sample can offer an **unbiased estimate** of the true population's parameters.


## Nothing Normal here

A binomial random variable is certainly not normal. 

```{r, echo=FALSE, fig.align="center"}
population <- rbinom(100,1,.3)
hist(population,xaxt='n',xlab='Survey Response',main='Binomial Distribution')
axis(1, at =  c(0,1), labels = c("No-0","Yes-1"), las=2)
```

But after 5,000 samples from the population...

```{r, echo=FALSE, fig.pos="H", fig.align="center"}
# Sample and compute x_bar_i; store; repeat
x_bar_i <- c()
x_bar_i <- replicate(10000, append(x_bar_i,mean(as.matrix(sample(population,10)))))

#plot
par(mfrow=c(1,2))
hist(population,xaxt='n',xlab='Survey Response',main='Binomial Distribution')
axis(1, at =  c(0,1), labels = c("No - 0","Yes - 1"), las=2)
# Compare frequency dist of x_bar_i to normal curve after 10000 samples
h<-hist(x_bar_i, breaks=20, col="blue", xlab="sample mean",main="10,000 Sample Means")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="red", lwd=2)
```

*How is this possible?*


## The Intuition

Consider a true population with a uniform distribution taking discrete values between 0 and 100 with a mean of 50:
```{r, echo=FALSE, fig.align="center"}
curve(dunif(x, min = 0, max = 100), from = -1, to = 101, n = 100000, col = "navy", lwd = 2
      ,ylab='Frequency',xlab='',main='')
abline(v = 50, col="navy", lwd=2, lty=2)
text(48, .005, "population mean", col = "navy",srt=90, cex=.75)
```

Pick two integers between 0 and 100 with a mean of 50. I chose 75 and 25, but there are many others.
```{r, echo=FALSE, fig.align="center"}
curve(dunif(x, min = 0, max = 100), from = -1, to = 101, n = 100000, col = "navy", lwd = 2
      ,ylab='Frequency',xlab='',main='')
abline(v = 25, col="red", lwd=1, lty=1)
abline(v = 75, col="red", lwd=1, lty=1)
abline(v = 50, col="navy", lwd=2, lty=2)
text(48, .005, "population mean", col = "navy",srt=90)
```

Now pick two integers between 0 and 100 with a mean of 5. There are far fewer options
```{r, echo=FALSE, fig.align="center"}
curve(dunif(x, min = 0, max = 100), from = -1, to = 101, n = 100000, col = "navy", lwd = 2
      ,ylab='Frequency',xlab='',main='')
abline(v = 2, col="red", lwd=1, lty=1)
abline(v = 8, col="red", lwd=1, lty=1)
abline(v = 5, col="red", lwd=2, lty=2)
text(3, .005, "mean = 5", col = "red",srt=90)
abline(v = 50, col="navy", lwd=2, lty=2)
text(48, .005, "population mean", col = "navy",srt=90)
```

**Result:** *The mean of your sample means is more likely to reflect the mean of the true population!*




## Proof through Monte Carlo Simulation

Let's consider the t-distribution.


### Theoretical Claim:

>>The frequency distribution of a random variable $bar{X}$ from a t distribution with 4 degrees of freedom and with n = 100 will follow a normal distribution around a mean of 0 (for a t distribution with df>1).


```{r, echo=FALSE, fig.align="center"}
population <- rt(1:100, df = 5)
hist(population, main='Frequency Distribution of RV ~ t')
```


#### Distribution & 25 Simulations:

The blue representing the normal curve shows our random variable is decided not normally distributed.

```{r, echo=TRUE, fig.pos="H", fig.align="center"}
# Sample and compute x_bar_i; store; repeat 24 times and check
x_bar_i <- c()
x_bar_i <- replicate(25, append(x_bar_i,mean(as.matrix(sample(population,10)))))

# Compare frequency dist of x_bar_i to normal curve after 50 samples
h<-hist(x_bar_i, breaks=20, col="light green", xlab="sample mean",
        main="10 Monte Carlos")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)
```


#### Simulate 100-1,000 times
```{r, echo=FALSE, fig.align="center"}
par(fig=c(0,.9,0,.9), mar=c(1,1,1,1),cex=.5)
#Run 100 simulations: 500 total
par(fig=c(0,0.45,.5,.9))
x_bar_i <- c()
x_bar_i <- replicate(100, append(x_bar_i,mean(as.matrix(sample(population,10)))))
# Compare frequency dist of x_bar_i to normal curve after 10,000 Monte Carlos
h<-hist(x_bar_i, breaks=20, col="green", xlab="sample mean",
        main="100 Monte Carlos")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)

#Run 250 simulations
par(fig=c(.5,.9,.5,.9),new=TRUE)
x_bar_i <- c()
x_bar_i <- replicate(250, append(x_bar_i,mean(as.matrix(sample(population,10)))))
# Compare frequency dist of x_bar_i to normal curve after 10,000 Monte Carlos
h<-hist(x_bar_i, breaks=20, col="chartreuse2", xlab="sample mean",
        main="250 Monte Carlos")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)

#Run 500 simulations
par(fig=c(0,.45,.0,.45),new=TRUE)
x_bar_i <- c()
x_bar_i <- replicate(500, append(x_bar_i,mean(as.matrix(sample(population,10)))))
# Compare frequency dist of x_bar_i to normal curve after 10,000 Monte Carlos
h<-hist(x_bar_i, breaks=20, col="chartreuse3", xlab="sample mean",
        main="500 Monte Carlos")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)

#Run 1000 simulations
par(fig=c(.5,.9,.0,.45),new=TRUE)
x_bar_i <- c()
x_bar_i <- replicate(1000, append(x_bar_i,mean(as.matrix(sample(population,10)))))
# Compare frequency dist of x_bar_i to normal curve after 10,000 Monte Carlos
h<-hist(x_bar_i, breaks=20, col="chartreuse4", xlab="sample mean",
        main="1000 Monte Carlos")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)
```



*Now, with 10,000 simulations, we can clearly see the frequency distribution of our sample means following a normal curve.*

```{r, echo=FALSE, fig.align="center"}
x_bar_i <- c()
#Run 10000 simulations
x_bar_i <- replicate(10000, append(x_bar_i,mean(as.matrix(sample(population,10)))))
# Compare frequency dist of x_bar_i to normal curve after 10,000 Monte Carlos
h<-hist(x_bar_i, breaks=20, col="dark green", xlab="sample mean",
        main="10,000 MCs Sample Means compared to Normal Curve")
xfit<-seq(min(x_bar_i),max(x_bar_i),length=40)
yfit<-dnorm(xfit,mean=mean(x_bar_i),sd=sd(x_bar_i))
yfit <- yfit*diff(h$mids[1:2])*length(x_bar_i)
lines(xfit, yfit, col="blue", lwd=2)
```